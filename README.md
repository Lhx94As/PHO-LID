# PHO-LID (Accepted to Interspeech 2022 as an oral presentation)[https://arxiv.org/abs/2203.12366]
PHO-LID: A Unified Model to Incorporate Acoustic-Phonetic and Phonotactic Information for Language Identification  

Some people have successfully reproduced the results (and achieved even better ones). There are no specific hyper-parameters or random seed, just remember to have a low number of nega_frame (see the config.json).  
  
DDP is not applicable during training, will try to update soon. Single-GPU training works well
